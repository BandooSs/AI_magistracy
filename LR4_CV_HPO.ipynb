{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder_path):\n",
    "    x_train = np.load(os.path.join(folder_path, 'x_train.npy'))\n",
    "    y_train = np.load(os.path.join(folder_path, 'y_train.npy'))\n",
    "    x_test = np.load(os.path.join(folder_path, 'x_test.npy'))\n",
    "    y_test = np.load(os.path.join(folder_path, 'y_test.npy'))\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_data('lr4_dataset/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной лабораторной работе будет практиковаться поиск гиперпараметров. Буду рассмотрены алгоритмы поиска гиперпараметров: grid search, random search.\n",
    "\n",
    "Помимо поиска гиперпараметров будет рассмотрен алгоритм кросс-валидации, позволяющий получить более достоверную оценку качества модели в условиях недостатка данных.\n",
    "Хотя в работе предоставлена тестовая выборка, она имеет сугубо теоретический характер (для получения финальной оценки) и на практике как правило недоступна. Поэтому во время подбора гиперпараметров используются лишь `x_train, y_train`. `x_test, y_test` используются лишь для получения финальной оценки, чтобы можно было видеть разницу между разными алгоритмами подбора гиперпараметров (если она будет).\n",
    "\n",
    "Выберите одну модель из списка: MLPClassifier, SGDClassifier, DecisionTreeClassifier, RandomForestClassifier, SVC.\n",
    "Для выбранной модели произведите поиск оптимальных гиперпараметров. Требование: поиск должен идти как минимум для двух гиперпараметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Обучение бейзлайн модели для проведения сравнения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тренировочная выборка имеет 110 экземпляров и 256 признаков\n",
      "Класса: 0 число элементов: 11\n",
      "Класса: 1 число элементов: 11\n",
      "Класса: 2 число элементов: 11\n",
      "Класса: 3 число элементов: 11\n",
      "Класса: 4 число элементов: 11\n",
      "Класса: 5 число элементов: 11\n",
      "Класса: 6 число элементов: 11\n",
      "Класса: 7 число элементов: 11\n",
      "Класса: 8 число элементов: 11\n",
      "Класса: 9 число элементов: 11\n"
     ]
    }
   ],
   "source": [
    "print(f\"Тренировочная выборка имеет {x_train.shape[0]} экземпляров и {x_train.shape[1]} признаков\")\n",
    "for count,num_class in zip(np.bincount(y_train),range(len(np.bincount(y_train)))):\n",
    "    print(f\"Класса: {num_class} число элементов: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестовая выборка имеет 30 экземпляров и 256 признаков\n",
      "Класса: 0 число элементов: 3\n",
      "Класса: 1 число элементов: 3\n",
      "Класса: 2 число элементов: 3\n",
      "Класса: 3 число элементов: 3\n",
      "Класса: 4 число элементов: 3\n",
      "Класса: 5 число элементов: 3\n",
      "Класса: 6 число элементов: 3\n",
      "Класса: 7 число элементов: 3\n",
      "Класса: 8 число элементов: 3\n",
      "Класса: 9 число элементов: 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Тестовая выборка имеет {x_test.shape[0]} экземпляров и {x_test.shape[1]} признаков\")\n",
    "for count,num_class in zip(np.bincount(y_test),range(len(np.bincount(y_test)))):\n",
    "    print(f\"Класса: {num_class} число элементов: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучите бейзлайн модель без изменения гиперпараметров (т.е. используются гиперпараметры по умолчанию).\n",
    "# Используйте результаты для дальнешейго анализа результатов.\n",
    "baseline_model = DecisionTreeClassifier()\n",
    "baseline_model.fit(x_train,y_train)\n",
    "y_pred_baseline = baseline_model.predict(x_test)\n",
    "# Напишите ваш код здесь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score_baseline_model = accuracy_score(y_test, y_pred_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты baseline_model на тестовой выборке:\n",
      "Число экземпляров всех трех классов [5 3 0 1 4 8 0 6 0 3]\n",
      "\n",
      "Число реальных экземпляров тестовой выборке:\n",
      "Число экземпляров всех трех классов [3 3 3 3 3 3 3 3 3 3]\n",
      "Точность baseline_model -> 0.4\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "        f\"Результаты baseline_model на тестовой выборке:\\nЧисло экземпляров всех трех классов {np.bincount(y_pred_baseline)}\")\n",
    "print(\n",
    "        f\"\\nЧисло реальных экземпляров тестовой выборке:\\nЧисло экземпляров всех трех классов {np.bincount(y_test)}\")\n",
    "print(f\"Точность baseline_model -> {accuracy_score_baseline_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_factory(param_dict=None):\n",
    "    if param_dict == None: return DecisionTreeClassifier()\n",
    "    return DecisionTreeClassifier(**param_dict)\n",
    "\n",
    "def accuracy_eval(labels, predictions):\n",
    "    return accuracy_score(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализуйте фунцию кросс-валидации\n",
    "\n",
    "# Замечание: x_test, y_test не должны применятся в рамках данной функции.\n",
    "\n",
    "def kfold_cv(model_fn, eval_fn, x: np.ndarray, y: np.ndarray, n_splits=5, param_dict=None) -> float:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_fn : callable\n",
    "        Функция-фабрика, что конструирует и возвращает новый объект модели.\n",
    "    eval_fn : callable\n",
    "        Функция вида `eval_fn(labels, predictions)`, что возвращает скаляр (значение метрики).\n",
    "    x : np.ndarray\n",
    "        Набор признаков (размерность NxD, N - количество экземпляро, D - количество признаков).\n",
    "    y : np.ndarray\n",
    "        Набор меток (размерность N)\n",
    "    n_splits : int, optional\n",
    "        Количество фолдов, по умолчанию 5.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Среднее значение метрики (что вычисляется eval_fn) по фолдам.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "    scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(x):\n",
    "        x_train_kfold, x_val = x[train_index], x[val_index]\n",
    "        y_train_kfold, y_val = y[train_index], y[val_index]\n",
    "        \n",
    "        model = model_fn(param_dict)  \n",
    "        model.fit(x_train_kfold, y_train_kfold)  \n",
    "\n",
    "        y_pred = model.predict(x_val)  \n",
    "\n",
    "        score = eval_fn(y_val, y_pred)  \n",
    "        scores.append(score)\n",
    "    \n",
    "    mean_score = np.mean(scores)\n",
    "    return mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Протестируйте функцию кросс-валидации. \n",
    "# Не производите поиск гиперпараметров, лишь убедитесь в корректности реализации фукнции kfold_cv.\n",
    "x_train, y_train, x_test, y_test = load_data('lr4_dataset/')\n",
    "mean_score_CV = kfold_cv(model_factory,accuracy_eval,x_train,y_train)\n",
    "# Напишите ваш код здесь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность  K-Fold Cross-Validation -> 0.2636363636363636\n"
     ]
    }
   ],
   "source": [
    "print(f\"Точность  K-Fold Cross-Validation -> {mean_score_CV}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во возможных вариантов по сетке:37\n",
      "{'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2} 0.4818181818181818\n"
     ]
    }
   ],
   "source": [
    "# 1. Реализуйте алгоритм поиска гиперпараметров grid search.\n",
    "# 2. Запустите поиск гиперпараметров, замерьте время работы алгоритма.\n",
    "# 3. Выведите найденные значения гиперпараметров и время работы.\n",
    "# Замечание: x_test, y_test не должны применятся в рамках данного алгоритма.\n",
    "# Замечание: убедитесь, что гиперпараметры по умолчанию включены в пространство поиска.\n",
    "# Требование: используйте kfold_cv для получения значения метрики в рамках одной итерации.\n",
    "x_train, y_train, x_test, y_test = load_data('lr4_dataset/')\n",
    "param_grid = {\n",
    "    'max_depth':         [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf':  [1, 2, 4]\n",
    "}\n",
    "\n",
    "all_params = list(product(*param_grid.values()))\n",
    "all_params.append(None)\n",
    "\n",
    "print(f\"Кол-во возможных вариантов по сетке:{len(all_params)}\")\n",
    "best_params = None\n",
    "best_score = 0.0\n",
    "start_time = time.time()\n",
    "for params in all_params:\n",
    "    if params is not None:\n",
    "        param_dict = dict(zip(param_grid.keys(), params))\n",
    "    else:\n",
    "        param_dict = params\n",
    "    mean_score = kfold_cv(model_factory,accuracy_eval,x_train,y_train,5,param_dict)\n",
    "    \n",
    "    if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_params = param_dict\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time        \n",
    "print(best_params,best_score)\n",
    "# Напишите ваш код здесь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используйте найденные гиперпараметры для обучения модели. \n",
    "# Протестируйте модель на x_test, y_test.\n",
    "# Сравните полученные результаты с теми, что получены в пункте 0.\n",
    "GS_model = DecisionTreeClassifier(**best_params)\n",
    "GS_model.fit(x_train,y_train)\n",
    "y_pred_GS_model = GS_model.predict(x_test)\n",
    "# Напишите ваш код здесь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score_GS_model = accuracy_score(y_test, y_pred_GS_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты Grid search_model на тестовой выборке:\n",
      "Число экземпляров всех трех классов [2 3 1 2 3 6 2 5 1 5]\n",
      "\n",
      "Число реальных экземпляров тестовой выборке:\n",
      "Число экземпляров всех трех классов [3 3 3 3 3 3 3 3 3 3]\n",
      "Точность Grid search_model -> 0.5333333333333333\n",
      "Время работы: 4.49 секунд\n",
      "Лучшие параметры Grid search_model: {'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2}\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "        f\"Результаты Grid search_model на тестовой выборке:\\nЧисло экземпляров всех трех классов {np.bincount(y_pred_GS_model)}\")\n",
    "print(\n",
    "        f\"\\nЧисло реальных экземпляров тестовой выборке:\\nЧисло экземпляров всех трех классов {np.bincount(y_test)}\")\n",
    "print(f\"Точность Grid search_model -> {accuracy_score_GS_model}\\nВремя работы: {execution_time:.2f} секунд\\nЛучшие параметры Grid search_model: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 0.4909090909090909\n"
     ]
    }
   ],
   "source": [
    "# 1. Реализуйте алгоритм поиска гиперпараметров random search.\n",
    "# 2. Запустите поиск гиперпараметров, замерьте время работы алгоритма.\n",
    "# 3. Выведите найденные значения гиперпараметров и время работы.\n",
    "# Замечание: x_test, y_test не должны применятся в рамках данного алгоритма.\n",
    "# Замечание: убедитесь, что гиперпараметры по умолчанию включены в пространство поиска.\n",
    "# Требование: используйте kfold_cv для получения значения метрики в рамках одной итерации.\n",
    "# Требование: количество итераций должно быть меньше в сравнении с grid search.\n",
    "param_grid = {\n",
    "    'max_depth': [5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "RS_best_params = None\n",
    "RS_best_score = 0.0\n",
    "start_time_RS = time.time()\n",
    "\n",
    "\n",
    "for _ in range(30):\n",
    "    my_value = [random.randint(5, 20), random.randint(2, 10), random.randint(1, 5)]\n",
    "    params = {param: value for param,value in zip(param_grid.keys(),my_value)}\n",
    "    mean_score = kfold_cv(model_factory,accuracy_eval,x_train,y_train,5,params)\n",
    "    if mean_score > RS_best_score:\n",
    "        RS_best_score = mean_score\n",
    "        RS_best_params = param_dict\n",
    "        \n",
    "mean_score = kfold_cv(model_factory,accuracy_eval,x_train,y_train,5,None)\n",
    "if mean_score > RS_best_score:\n",
    "    RS_best_score = mean_score\n",
    "    RS_best_params = param_dict\n",
    "end_time_RS = time.time()\n",
    "execution_time_RS = end_time_RS - start_time_RS\n",
    "print(RS_best_params,RS_best_score)\n",
    "\n",
    "# Напишите ваш код здесь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используйте найденные гиперпараметры для обучения модели. \n",
    "# Протестируйте модель на x_test, y_test.\n",
    "# Сравните полученные результаты с теми, что получены в пункте 0.\n",
    "# Сравните полученные результаты с теми, что получены в пункте 2.`\n",
    "if RS_best_params == None:\n",
    "    RS_model = DecisionTreeClassifier()\n",
    "else: \n",
    "    RS_model = DecisionTreeClassifier(**RS_best_params)\n",
    "RS_best_params = RS_model.get_params()\n",
    "RS_model.fit(x_train,y_train)\n",
    "y_pred_RS = RS_model.predict(x_test)\n",
    "# Напишите ваш код здесь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "RS_best_params = {'max_depth': RS_best_params['max_depth'],\n",
    "                'min_samples_split': RS_best_params['min_samples_split'],\n",
    "                    'min_samples_leaf': RS_best_params['min_samples_leaf']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score_RS = accuracy_score(y_test, y_pred_RS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты Grid search_model на тестовой выборке:\n",
      "Число экземпляров всех трех классов [2 3 1 0 6 8 2 5 1 2]\n",
      "\n",
      "Число реальных экземпляров тестовой выборке:\n",
      "Число экземпляров всех трех классов [3 3 3 3 3 3 3 3 3 3]\n",
      "Точность Random search_model -> 0.5\n",
      "Время работы: 3.72 секунд\n",
      "Лучшие параметры Random search_model:{'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "        f\"Результаты Grid search_model на тестовой выборке:\\nЧисло экземпляров всех трех классов {np.bincount(y_pred_RS)}\")\n",
    "print(\n",
    "        f\"\\nЧисло реальных экземпляров тестовой выборке:\\nЧисло экземпляров всех трех классов {np.bincount(y_test)}\")\n",
    "print(f\"Точность Random search_model -> {accuracy_score_RS}\\nВремя работы: {execution_time_RS:.2f} секунд\\nЛучшие параметры Random search_model:{RS_best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность baseline_model -> 0.400\n",
      "\n",
      "Точность  K-Fold Cross-Validation -> 0.264\n",
      "\n",
      "Точность Random search_model -> 0.500\n",
      "Время работы: 3.72 секунд\n",
      "Лучшие параметры Random search_model:{'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1}\n",
      "\n",
      "Точность Grid search_model -> 0.533\n",
      "Время работы: 4.49 секунд\n",
      "Лучшие параметры Grid search_model: {'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Точность baseline_model -> {accuracy_score_baseline_model:.3f}\\n\")\n",
    "print(f\"Точность  K-Fold Cross-Validation -> {mean_score_CV:.3f}\\n\")\n",
    "print(f\"Точность Random search_model -> {accuracy_score_RS:.3f}\\nВремя работы: {execution_time_RS:.2f} секунд\\nЛучшие параметры Random search_model:{RS_best_params}\\n\")\n",
    "print(f\"Точность Grid search_model -> {accuracy_score_GS_model:.3f}\\nВремя работы: {execution_time:.2f} секунд\\nЛучшие параметры Grid search_model: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из результов видно, что Grid Search показал лучший результат, но требовал больше времени по сравнению с Random Search. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Доп. задание (опционально)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Bayesian optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените байесовскую оптимизацию для поиска гиперпараметров.\n",
    "В качестве алгоритма используйте `BayesSearchCV` из пакета `scikit-optimize`.\n",
    "\n",
    "Сложность: почти бесплатный балл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используйте найденные гиперпараметры для обучения модели. \n",
    "# Протестируйте модель на x_test, y_test.\n",
    "# Сравните полученные результаты с теми, что получены в пункте 0.\n",
    "# Сравните полученные результаты с теми, что получены в пункте 2.\n",
    "\n",
    "# Напишите ваш код здесь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Tree of Parzen Estimators (TPE) из HyperOpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените TPE из библиотеки hyperopt для поиска гиперпараметров. Вики по HyperOpt: https://github.com/hyperopt/hyperopt/wiki/FMin\n",
    "\n",
    "Сложность: чтец документаций o(*￣▽￣*)ブ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(args):\n",
    "    # Принимает гиперпараметры, инстанцирует модель, обучает её, возвращает значение метрики.\n",
    "    # Замечание: x_test, y_test не должны применятся в рамках данного алгоритма.\n",
    "    \n",
    "    # Напишите ваш код здесь.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определите пространство поиска гиперпараметров\n",
    "space = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Запустите поиск гиперпараметров, замерьте время работы алгоритма.\n",
    "# 2. Выведите найденные значения гиперпараметров и время работы.\n",
    "\n",
    "# Напишите ваш код здесь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используйте найденные гиперпараметры для обучения модели. \n",
    "# Протестируйте модель на x_test, y_test.\n",
    "# Сравните полученные результаты с теми, что получены в пункте 0.\n",
    "# Сравните полученные результаты с теми, что получены в пункте 2.\n",
    "\n",
    "# Напишите ваш код здесь."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "23b26f1881f590c7b459213b984520b9808dddee0bcd327e09d3f0f8eaeae1aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
